{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb5e04d",
   "metadata": {},
   "source": [
    "# OpenAI API Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941ab60",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Understand how OpenAI's Python SDK authenticates and selects models.\n",
    "- Practice crafting prompts for neurosurgical reasoning, patient education, and documentation.\n",
    "- Capture structured outputs (JSON) that can flow into operative notes or registries.\n",
    "- Explore embeddings, images, audio, and vision workflows that turn LLMs into multi-modal teammates.\n",
    "- Adopt safety measures so experimental code never substitutes for real clinical decision making.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c16f477",
   "metadata": {},
   "source": [
    "## Prerequisites & setup\n",
    "\n",
    "- Create an OpenAI account and generate an API key with access to the models used below.\n",
    "- Store your key in an environment variable (e.g., `OPENAI_API_KEY`) and let `api_key.py` read it at runtime.\n",
    "- Install Python 3.10+ plus the packages referenced here. If you are running in a clean environment uncomment the `pip` command in the next cell.\n",
    "- All examples default to lightweight, cost-efficient models so you can iterate quickly and upgrade to bigger models when you need higher fidelity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade \"openai>=1.40.0\" numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cc1d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready! Text model: gpt-4o-mini, embedding model: text-embedding-3-large\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "import api_key\n",
    "\n",
    "client = OpenAI(api_key=api_key.openai)\n",
    "default_model = \"gpt-4o-mini\"\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "\n",
    "print(f\"Ready! Text model: {default_model}, embedding model: {embedding_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935447e3",
   "metadata": {},
   "source": [
    "### Helper utilities\n",
    "\n",
    "A couple of helper functions keep the later sections tidy. `print_response` mirrors what you would do when you log the assistant's output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3098e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(text, width=90):\n",
    "    print(textwrap.fill(text, width=width))\n",
    "\n",
    "def print_response(resp):\n",
    "    \"\"\"Utility for printing the text output of Responses API calls.\"\"\"\n",
    "    wrap(resp.output_text.strip())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c60011",
   "metadata": {},
   "source": [
    "## 1. First warm up\n",
    "\n",
    "Patient education via LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b8079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "warmup_prompt = \"\"\"You are prepping a patient for a L4-L5 microdiscectomy and consenting them in the clinic for the same.\n",
    "Explain in ~120 words what will happen in the operating room and how the decompression\n",
    "relieves leg pain. Avoid giving promises or numerical risks; instead focus on the flow\n",
    "of the day and what sensations the patient may or may not notice.\"\"\"\n",
    "\n",
    "warmup_response = client.responses.create(\n",
    "    model=default_model,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a friendly neurosurgery resident. Keep explanations accurate and calming.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": warmup_prompt},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e162bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the operating room, you’ll be given anesthesia to ensure you’re comfortable and relaxed\n",
      "throughout the procedure. Once you're asleep, the surgeon will make a small incision in\n",
      "your lower back to access the L4-L5 area. Using a microscope, they’ll carefully remove the\n",
      "herniated disc material that’s pressing on the nerves. This decompression helps relieve\n",
      "leg pain by allowing the nerves to return to their normal state, reducing irritation and\n",
      "inflammation. You may wake up in the recovery area feeling groggy, but many patients\n",
      "notice a significant difference in their leg pain soon after the procedure. The team will\n",
      "monitor you closely to ensure your comfort and safety as you recover.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_response(warmup_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee85ef7",
   "metadata": {},
   "source": [
    "### What did the API return?\n",
    "\n",
    "The Responses API returns a structured object that includes the model name, token usage, finish reasons, and the text blocks produced. Inspecting this metadata helps you judge cost, latency, and reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60792662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'finish_reason': ResponseOutputMessage(id='msg_07da48ea6cf38b6900693e115889fc819384754562c9b0006b', content=[ResponseOutputText(annotations=[], text=\"In the operating room, you’ll receive sedation to ensure you're comfortable. Once you're asleep, the surgeon will make a small incision in your lower back to access the L4-L5 area. They'll carefully remove the portion of the herniated disc that’s pressing on the nerve root, which is causing your leg pain. After the decompression, the pressure on the nerve will be relieved, often leading to reduced pain and improved mobility. You might feel some sensations as you wake up, but we'll manage any discomfort effectively. Recovery will start right away, and our team will be there to support you throughout the process.\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message'),\n",
      " 'model': 'gpt-4o-mini-2024-07-18',\n",
      " 'usage': ResponseUsage(input_tokens=101, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=124, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=225)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pprint(\n",
    "    {\n",
    "        \"model\": warmup_response.model,\n",
    "        \"usage\": warmup_response.usage,\n",
    "        \"finish_reason\": warmup_response.output[0],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe8107",
   "metadata": {},
   "source": [
    "## Basics of Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models (LLMs) like GPT-4o or GPT-4o-mini are neural networks trained on trillions of tokens so they learn statistical patterns of language and reasoning. They operate token-by-token: given previous tokens plus the prompt, the model predicts probabilities for the next token, samples one, then repeats until a stop condition or max length. The art of using LLMs therefore revolves around understanding tokens and the knobs that shape each sampling step.\n",
    "\n",
    "### Tokens and context windows\n",
    "- **Tokens** are the smallest text chunks the model sees (roughly a word or part of a word). Pricing, latency, and limits are all measured in tokens.\n",
    "- **Context windows** cap how many tokens the model can process at once (e.g., 128k tokens). Both input and output tokens count toward this limit.\n",
    "- **Counting tokens** up front avoids truncation: mind the `max_output_tokens` you request versus the remaining room in the context window.\n",
    "\n",
    "### Parameters you can tune in API calls\n",
    "| Parameter | What it controls | When to raise | When to lower | Example |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| `temperature` | Scales randomness during sampling. 0 = deterministic, 1 = creative. | Brainstorming, dialogue, creative writing. | Instructions, coding, summarization. | `temperature=0.2` for precise Q&A, `temperature=0.8` for ideation. |\n",
    "| `top_p` (nucleus sampling) | Keeps only the smallest set of tokens whose probabilities sum to `p`. | When you want open-ended but coherent text. | When you need strict determinism. | `top_p=0.9` keeps ~90% cumulative probability mass. |\n",
    "| `top_k` | Restricts sampling to the top-k most likely tokens. | When platform exposes it (Anthropic, Google, some OpenAI betas) and you want controlled diversity. | When chasing single best answer. | `top_k=40` only considers the 40 most probable tokens. |\n",
    "| `max_output_tokens` | Hard cap on generated length. | Prevent verbose responses, control spend. | Need longer explanations or documents. | `max_output_tokens=256` for summaries, `1024` for reports. |\n",
    "| `presence_penalty` | Penalizes using tokens already present in the prompt/output, nudging new topics. | Encourage model to explore new ideas. | Preserve topic repetition (e.g., keyword stuffing). | `presence_penalty=0.3` to avoid repeating the same sentence. |\n",
    "| `frequency_penalty` | Penalizes repeating the same token multiple times. | Remove loops and redundant wording. | Preserve repetition (poetry, chants). | `frequency_penalty=0.5` to keep lists concise. |\n",
    "| `stop` / `stop_sequences` | Strings that halt generation when hit. | Force the model to hand control back to you. | Rarely. Use only if you truly need to cut output. | `stop=[\"Observation:\"]` in ReAct workflows. |\n",
    "| `logprobs` / `logit_bias` | Inspect or alter token probabilities. | Debugging, constraining to specific outputs. | Most production flows. | `logit_bias={\"</s>\": -100}` to block EOS. |\n",
    "| `response_format` / `json_schema` | Forces strict JSON or structured replies when supported. | Building agents and tools that parse responses. | Free-form prose. | `response_format={\"type\":\"json_schema\",\"json_schema\":...}`. |\n",
    "| `seed` | Makes sampling reproducible when supported. | Testing, demos. | Production (unless determinism desired). | `seed=123` for consistent completions. |\n",
    "\n",
    "> **Rule of thumb:** `temperature`, `top_p`, and `top_k` all affect randomness—tweak only one or two at a time to understand the change. Penalties reshape style, while max tokens, stop signals, and response formats control structure.\n",
    "\n",
    "### Example API call with tuned parameters\n",
    "```python\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"Explain the Krebs cycle simply.\"}],\n",
    "    temperature=0.3,\n",
    "    top_p=0.85,\n",
    "    top_k=40,\n",
    "    max_output_tokens=220,\n",
    "    presence_penalty=0.2,\n",
    "    frequency_penalty=0.2,\n",
    "    stop=[\"Teacher:\"]\n",
    ")\n",
    "print(resp.output_text)\n",
    "```\n",
    "- Increase `temperature`/`top_p` for more imaginative analogies.\n",
    "- Lower `temperature`/`top_p` and add stricter penalties for factual, step-by-step explanations.\n",
    "- Raise `max_output_tokens` whenever the answer needs room (e.g., multi-section reports).\n",
    "\n",
    "Experimenting with these knobs—and logging both prompts and parameter sets—helps you converge on predictable behavior for each task while keeping costs and latency under control.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33990a02",
   "metadata": {},
   "source": [
    "## 2. Clinical reasonin\n",
    "\n",
    "Graduate from education to reasoning. The prompt below simulates a spine-call text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810c65e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Likely Diagnoses\n",
      "1. **Cauda Equina Syndrome (CES)**: The combination of saddle anesthesia, urinary hesitancy, and bilateral plantar-flexion weakness suggests potential involvement of the cauda equina due to the large central disc extrusion at L5-S1.\n",
      "2. **Lumbar Disc Herniation**: The MRI findings indicate a significant disc extrusion, which could be causing nerve root compression.\n",
      "3. **Post-Surgical Complications**: Given the history of lumbar fusion, there may be complications such as scar tissue or recurrent disc herniation.\n",
      "\n",
      "### Key Red Flags\n",
      "- **Saddle Anesthesia**: Indicates possible cauda equina involvement.\n",
      "- **Urinary Hesitancy**: Suggests potential bladder dysfunction, a hallmark of CES.\n",
      "- **Bilateral Weakness**: Indicates possible bilateral nerve root involvement, which is concerning for CES.\n",
      "- **Recent Fall**: Could indicate a traumatic event leading to acute changes.\n",
      "\n",
      "### Next Two Actions Before Calling the Attending\n",
      "1. **Obtain Neurological Examination**: Perform a thorough neurological exam to assess motor strength, sensory function, and reflexes. This will help quantify the extent of neurological deficits and provide critical information for the attending.\n",
      "   \n",
      "2. **Review MRI Findings**: Ensure that the MRI report is available and review the imaging for the degree of canal compromise and any other potential findings (e.g., spinal stenosis, other lesions). If the images are not available, request them to be sent for evaluation.\n",
      "\n",
      "### Pending Data\n",
      "- **Neurological Exam Results**: Need to assess the current neurological status in detail.\n",
      "- **MRI Images**: Confirm the extent of the disc extrusion and any other relevant findings.\n",
      "- **Urinary Function Assessment**: Consider a bladder scan to evaluate post-void residual volume, which would provide insight into bladder function.\n",
      "\n",
      "After these actions, I would be prepared to discuss the case with the attending, including the urgency of potential surgical intervention given the signs of CES.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "case_study = \"\"\"47-year-old with a history of lumbar fusion now presents with 10 days of worsening\n",
    "saddle anesthesia, urinary hesitancy, and bilateral plantar-flexion weakness after a fall.\n",
    "MRI from outside hospital shows a large central disc extrusion at L5-S1 with severe canal compromise.\n",
    "Summarize likely diagnoses, key red flags, and the next two actions you would take before\n",
    "calling the attending. Limit yourself to evidence-based guidance and highlight when data is missing.\"\"\"\n",
    "\n",
    "case_response = client.responses.create(\n",
    "    model=default_model,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are the chief neurosurgery resident. Think step-by-step and state when imaging or labs are pending.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": case_study,\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print_response(case_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4cc61",
   "metadata": {},
   "source": [
    "### Bonus: streaming live tokens (optional)\n",
    "\n",
    "If you want the interface to feel more conversational, use streaming. The snippet below prints tokens as they arrive so a learner can see the thought process unfold. Remove the triple quotes and run it when you have time to experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57832f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up an Intracranial Pressure (ICP) monitor requires strict adherence to sterile techniques to minimize the risk of infection. Here are the typical steps for a sterile setup:\n",
      "\n",
      "### 1. **Gather Materials:**\n",
      "   - ICP monitor device\n",
      "   - Intracranial catheter (e.g., for ventricle)\n",
      "   - Sterile drapes\n",
      "   - Sterile gloves\n",
      "   - Antiseptic solution (e.g., chlorhexidine)\n",
      "   - Sterile gauze and sponges\n",
      "   - Sterile tubing (if applicable)\n",
      "   - Syringe and sterile saline (for calibration)\n",
      "   - Sterile tape or securement device\n",
      "\n",
      "### 2. **Preparation of the Environment:**\n",
      "   - Ensure the procedure area is clean and as sterile as possible.\n",
      "   - Use a sterile field or drape to cover the area where the setup will occur.\n",
      "\n",
      "### 3. **Hand Hygiene:**\n",
      "   - Perform hand hygiene thoroughly using an antiseptic solution or hand sanitizer.\n",
      "\n",
      "### 4. **Aseptic Technique:**\n",
      "   - Put on sterile gloves.\n",
      "   - Maintain a sterile field; avoid touching non-sterile surfaces.\n",
      "\n",
      "### 5. **Preparation of the Catheter:**\n",
      "   - Open the sterile packaging of the ICP catheter without contaminating the tip.\n",
      "   - Attach necessary connectors and ensure they are tightly secured.\n",
      "\n",
      "### 6. **Antiseptic Application:**\n",
      "   - Clean the insertion site (e.g., scalp or skull) with antiseptic solution.\n",
      "   - Allow it to dry completely to ensure effective antimicrobial action.\n",
      "\n",
      "### 7. **Insertion:**\n",
      "   - Following proper technique, insert the ICP catheter into the predetermined location (e.g., ventricle or subdural space).\n",
      "   - Use a sterile technique throughout the insertion process, avoiding contact with non-sterile items.\n",
      "\n",
      "### 8. **Connecting the Monitor:**\n",
      "   - Connect the ICP catheter to the monitoring system while maintaining sterility.\n",
      "   - Ensure all connections are secure; use sterile tubing if required.\n",
      "\n",
      "### 9. **Calibration:**\n",
      "   - If necessary, calibrate the ICP monitor according to the manufacturer's instructions using sterile saline.\n",
      "\n",
      "### 10. **Secure the Setup:**\n",
      "   - Use sterile tape or securement devices to stabilize the catheter and monitor.\n",
      "   - Ensure that all components are appropriately positioned and secured.\n",
      "\n",
      "### 11. **Final Checks:**\n",
      "   - Verify that the system functions properly and check for any leaks.\n",
      "   - Document the procedure and setup details for medical records.\n",
      "\n",
      "### 12. **Monitor Patient:**\n",
      "   - Continuously monitor the patient's vital signs and ICP readings following the setup.\n",
      "\n",
      "### 13. **Post-setup Maintenance:**\n",
      "   - Regularly check the site for signs of infection or complications.\n",
      "   - Follow protocols for maintenance and care of the ICP monitoring system.\n",
      "\n",
      "These steps may vary slightly based on specific institutional protocols or the type of ICP monitor being used, so always refer to local guidelines and manufacturer's instructions."
     ]
    }
   ],
   "source": [
    "from contextlib import suppress\n",
    "from openai import Stream\n",
    "\n",
    "with client.responses.stream(\n",
    "    model=default_model,\n",
    "    input=[{\"role\": \"user\", \"content\": \"List sterile setup steps SOP for an ICP monitor.\"}],\n",
    ") as stream:\n",
    "    for event in stream:\n",
    "        if event.type == \"response.output_text.delta\":\n",
    "            print(event.delta, end=\"\", flush=True)\n",
    "    final_response = stream.get_final_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e67bdb",
   "metadata": {},
   "source": [
    "## 3. Structured operative notes with JSON output\n",
    "\n",
    "Operative summaries often need to land in registries or EMRs. The `response_format` parameter enforces a JSON schema so the assistant cannot hallucinate field names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06e1b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key_findings': ['Recurrent left temporal low-grade glioma',\n",
      "                  'Slow growth bordering language cortex on recent MRI',\n",
      "                  'Neurologic status intact'],\n",
      " 'next_steps': ['Obtain updated labs',\n",
      "                'Complete DTI tractography',\n",
      "                'Get anesthesia clearance for awake craniotomy technique'],\n",
      " 'patient_summary': '35-year-old with recurrent left temporal low-grade '\n",
      "                    'glioma. Neurologic exam is intact.',\n",
      " 'surgical_priority': 'elective'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "structured_prompt = \"\"\"Summarize the key details from this case presentation for the operative board.\n",
    "Emphasize neurologic status, imaging, and what still needs clarification.\n",
    "Case: 35-year-old with recurrent left temporal low-grade glioma. Neuro exam intact.\n",
    "Recent MRI: slow growth bordering language cortex. Plan for awake craniotomy with mapping.\n",
    "Pending: updated labs, DTI tractography, and anesthesia clearance for awake technique.\"\"\"\n",
    "\n",
    "\n",
    "schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"postop_note\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"patient_summary\": {\"type\": \"string\"},\n",
    "            \"surgical_priority\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"elective\", \"urgent\", \"emergent\"],\n",
    "            },\n",
    "            \"key_findings\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "            },\n",
    "            \"next_steps\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"patient_summary\", \"surgical_priority\", \"key_findings\", \"next_steps\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True\n",
    "}\n",
    "\n",
    "structured_response = client.responses.create(\n",
    "    model=default_model,\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Return concise clinical facts only.\"},\n",
    "        {\"role\": \"user\", \"content\": structured_prompt},\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": schema\n",
    "    } # type: ignore\n",
    "    \n",
    ")\n",
    "\n",
    "patient_note = json.loads(structured_response.output_text)\n",
    "pprint(patient_note)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb9c97",
   "metadata": {},
   "source": [
    "## 4. Build a focused knowledge base with embeddings\n",
    "\n",
    "Embeddings convert text into vectors so we can search our own notes. Below we encode three short neurosurgery guidelines, then ask the model which passages best answer a resident question. Cosine similarity identifies candidate references before you feed them to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86d5fbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cauda equina workup (cosine=0.595)\n",
      "New saddle anesthesia, sphincter dysfunction, or progressive weakness warrants emergent MRI with\n",
      "contrast. Decompress within 24 hours when deficits present.\n",
      "\n",
      "Spine trauma activation (cosine=0.495)\n",
      "Immobilize, obtain CT first, and screen for hemodynamic instability before MRI. Rapid neuro checks\n",
      "every 30 minutes until OR.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neurosurgery_notes = [\n",
    "    {\n",
    "        \"title\": \"Spine trauma activation\",\n",
    "        \"text\": \"Immobilize, obtain CT first, and screen for hemodynamic instability before MRI. Rapid neuro checks every 30 minutes until OR.\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Cauda equina workup\",\n",
    "        \"text\": \"New saddle anesthesia, sphincter dysfunction, or progressive weakness warrants emergent MRI with contrast. Decompress within 24 hours when deficits present.\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Pituitary apoplexy\",\n",
    "        \"text\": \"Look for sudden headache, ophthalmoplegia, and visual loss. Give stress-dose steroids, obtain MRI sellar protocol, and call endocrine for hormone replacement.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "note_embeddings = client.embeddings.create(\n",
    "    model=embedding_model,\n",
    "    input=[note[\"text\"] for note in neurosurgery_notes],\n",
    ")\n",
    "\n",
    "note_matrix = np.vstack([np.array(data.embedding) for data in note_embeddings.data])\n",
    "note_matrix = note_matrix / np.linalg.norm(note_matrix, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def search_notes(question, top_k=2):\n",
    "    query_embedding = client.embeddings.create(model=embedding_model, input=question).data[0].embedding\n",
    "    query_vec = np.array(query_embedding)\n",
    "    query_vec = query_vec / np.linalg.norm(query_vec)\n",
    "    scores = note_matrix @ query_vec\n",
    "    best_indices = scores.argsort()[::-1][:top_k]\n",
    "    return [\n",
    "        {\n",
    "            \"title\": neurosurgery_notes[idx][\"title\"],\n",
    "            \"score\": float(scores[idx]),\n",
    "            \"text\": neurosurgery_notes[idx][\"text\"],\n",
    "        }\n",
    "        for idx in best_indices\n",
    "    ]\n",
    "\n",
    "results = search_notes(\"How should I image suspected cauda equina and what timing is ideal?\")\n",
    "for row in results:\n",
    "    print(f\"{row['title']} (cosine={row['score']:.3f})\")\n",
    "    wrap(row[\"text\"], width=100)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5fdd5",
   "metadata": {},
   "source": [
    "Once you have the top passages you can pass them back into `client.responses.create` as context so the model cites your own material rather than guessing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7568e76",
   "metadata": {},
   "source": [
    "## 5. Vision-informed Results\n",
    "\n",
    "`gpt-4o-mini` can accept both text and images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165bc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This painting is \"The Starry Night\" by Vincent van Gogh, created in 1889. It depicts a\n",
      "swirling night sky filled with vibrant stars and a bright crescent moon, set against a\n",
      "backdrop of deep blues.   In the foreground, a large, dark cypress tree rises, often\n",
      "interpreted as a symbol of death but also a connection between the earth and the sky. The\n",
      "swirling patterns in the sky suggest movement and emotion, expressing van Gogh’s turbulent\n",
      "state of mind at the time. The bright yellows and whites of the stars contrast with the\n",
      "deep blues and greens, creating a sense of wonder and dynamism.   The painting reflects\n",
      "van Gogh's unique style, characterized by bold brushstrokes and a vibrant color palette,\n",
      "capturing both beauty and emotional depth. It invites viewers to contemplate the mysteries\n",
      "of the universe and the artist’s inner turmoil.\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://sanctuarymentalhealth.org/wp-content/uploads/2021/03/The-Starry-Night-1200x630-1.jpg.webp\"\n",
    "\n",
    "vision_response = client.responses.create(\n",
    "    model=default_model,\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"expalin this painting to me\",\n",
    "                },\n",
    "                {\"type\": \"input_image\", \"image_url\": image_url}, # type: ignore\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print_response(vision_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5f51b",
   "metadata": {},
   "source": [
    "## 6. Generating narrated briefings\n",
    "\n",
    "Here is how to generate an educationala narrated briefing. Remember to store the file path if you want to share it later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b17c9c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'message': 'Your organization must be verified to use the model `gpt-image-1`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m education_prompt = \u001b[33m\"\u001b[39m\u001b[33mCreate a clean, calming educational poster that explains what to expect after cervical disc arthroplasty. Use teal and white colors, include icons for pain control, wound care, and activity limits.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m image = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-image-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43meducation_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1024x1024\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m image_url = image.data[\u001b[32m0\u001b[39m].url\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShare this URL:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/basic/lib/python3.14/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/basic/lib/python3.14/site-packages/openai/resources/images.py:879\u001b[39m, in \u001b[36mImages.generate\u001b[39m\u001b[34m(self, prompt, background, model, moderation, n, output_compression, output_format, partial_images, quality, response_format, size, stream, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    851\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    877\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    878\u001b[39m ) -> ImagesResponse | Stream[ImageGenStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/images/generations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmoderation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_compression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpartial_images\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstyle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParamsStreaming\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageGenStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/basic/lib/python3.14/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/basic/lib/python3.14/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': {'message': 'Your organization must be verified to use the model `gpt-image-1`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "\n",
    "education_prompt = \"Create a clean, calming educational poster that explains what to expect after cervical disc arthroplasty. Use teal and white colors, include icons for pain control, wound care, and activity limits.\"\n",
    "\n",
    "image = client.images.generate(\n",
    "    model=\"gpt-image-1\",\n",
    "    prompt=education_prompt,\n",
    "    size=\"1024x1024\",\n",
    ")\n",
    "\n",
    "image_url = image.data[0].url\n",
    "print(\"Share this URL:\")\n",
    "print(image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "287e9f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved narrated briefing to /Users/bdthombre/developer/python/python_tutorial/002_langchain/patient_briefing.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/q4m5py2d3vb6nndpxvvs7mk40000gn/T/ipykernel_19501/2018354007.py:11: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  audio_response.stream_to_file(output_path)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "speech_text = \"You may feel throat soreness and shoulder tightness after surgery. Keep your collar on, walk every few hours, and call if you notice new weakness, fevers, or difficulty swallowing. We are always on call for you.\"\n",
    "\n",
    "audio_response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",\n",
    "    # format=\"mp3\",\n",
    "    input=speech_text,\n",
    ")\n",
    "\n",
    "output_path = Path(\"patient_briefing.mp3\")\n",
    "audio_response.stream_to_file(output_path)\n",
    "print(f\"Saved narrated briefing to {output_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31119c",
   "metadata": {},
   "source": [
    "## 7. Safety checklist and next steps\n",
    "\n",
    "- **De-identify everything.** Never paste MRNs, dates of birth, or other PHI into prompts.\n",
    "- **Label educational use.** Students should know these are coaching aids, not chart-ready notes.\n",
    "- **Track costs.** `warmup_response.usage` shows token counts—log them if you plan to share notebooks broadly.\n",
    "- **Add guardrails.** Combine embeddings + prompting to keep outputs anchored in approved institutional guidelines.\n",
    "- **Experiment mindfully.** Try swapping `gpt-4o` for complex reasoning or `gpt-4o-mini` for labs with limited budgets.\n",
    "\n",
    "### Suggested practice exercises\n",
    "\n",
    "1. Swap in one of your own de-identified consult notes and see how structured JSON output changes.\n",
    "2. Expand the embeddings dataset with departmental protocols, then build a simple retrieval-augmented generation (RAG) helper.\n",
    "3. Create a function tool that performs a quick NIHSS calculation and let the LLM decide when to call it.\n",
    "4. Prototype a Gradio or Streamlit UI that wraps the prompts you liked best.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
