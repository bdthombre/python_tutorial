{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eafa5bdf",
   "metadata": {},
   "source": [
    "# Streamlit UI basics → PDF RAG chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe7d58",
   "metadata": {},
   "source": [
    "We will first build a tiny Streamlit playground to understand widgets and layout, then reuse those ideas to ship a Retrieval-Augmented Generation (RAG) PDF chat experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0580cbdb",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Install the UI + parsing dependencies before running the notebook or Streamlit apps.\n",
    "\n",
    "```bash\n",
    "pip install streamlit pypdf numpy openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2d2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install streamlit pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a794a71",
   "metadata": {},
   "source": [
    "## Part 1 – Streamlit UI fundamentals\n",
    "The goal is to understand how Streamlit scripts read inputs, update session state, and render widgets instantly each time the script reruns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e240a59",
   "metadata": {},
   "source": [
    "### Basic playground features\n",
    "- sidebar sliders/select boxes for quick controls\n",
    "- text/text-area widgets bound to `st.session_state`\n",
    "- tables and metrics that update whenever inputs change\n",
    "- a simple chart driven by NumPy so you see how plotting works without extra libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9635cc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bdthombre/developer/python/python_tutorial/003_streamlit_ui/streamlit_basics_demo.py\n",
      "\"\"\"Small Streamlit playground for teaching the core widgets.\"\"\"\n",
      "\n",
      "from __future__ import annotations\n",
      "\n",
      "import numpy as np\n",
      "import streamlit as st\n",
      "\n",
      "st.set_page_config(page_title=\"Streamlit basics\", page_icon=\"✨\", layout=\"wide\")\n",
      "st.title(\"Streamlit basics playground\")\n",
      "st.write(\n",
      "    \"This mini-app highlights the most common Streamlit patterns: layout, widgets, \"\n",
      "    \"callbacks, and live charts.\"\n",
      ")\n",
      "\n",
      "with st.sidebar:\n",
      "    st.header(\"Sidebar controls\")\n",
      "    energy = st.slider(\"How energetic is today's session?\", 0, 10, 6)\n",
      "    mood = st.selectbox(\"Room mood\", [\"Curious\", \"Focused\", \"Sleepy\", \"Hyped\"], index=1)\n",
      "    st.write(f\"Energy: {energy} ⚡️ · Mood: {mood}\")\n",
      "\n",
      "name = st.text_input(\"What's your name?\", placeholder=\"Type and press enter\")\n",
      "note = st.text_area(\n",
      "    \"What was the most interesting idea today?\",\n",
      "    placeholder=\"Widgets, layout, or charts?\",\n",
      "    height=100,\n",
      ")\n",
      "\n",
      "if \"notes\" not in st.session_state:\n",
      "    st.session_state.notes = []\n",
      "\n",
      "cols = st.columns(2)\n",
      "with cols[0]:\n",
      "    st.metric(\"Total notes\", len(st.session_state.notes))\n",
      "with cols[1]:\n",
      "    show_chart = st.toggle(\"Live chart\", value=True)\n",
      "\n",
      "if st.button(\"Add note\", type=\"primary\", disabled=not note.strip()):\n",
      "    st.session_state.notes.append({\"name\": name or \"Anonymous\", \"note\": note.strip()})\n",
      "    st.success(\"Saved! Add another insight if you like.\")\n",
      "\n",
      "if st.session_state.notes:\n",
      "    st.subheader(\"Collected insights\")\n",
      "    st.table(st.session_state.notes)\n",
      "else:\n",
      "    st.info(\"Use the form above to add your first note.\")\n",
      "\n",
      "if show_chart:\n",
      "    st.subheader(\"Random learning velocity\")\n",
      "    chart_data = np.cumsum(np.random.randn(20, 3), axis=0)\n",
      "    st.line_chart(chart_data, height=260)\n",
      "\n",
      "st.caption(\n",
      "    \"Try editing this file to experiment with new widgets. Streamlit hot-reloads whenever you save.\"\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "basics_path = Path('./streamlit_basics_demo.py')\n",
    "print(basics_path.resolve())\n",
    "print(\"\\n\".join(basics_path.read_text().splitlines()[:80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b9caf",
   "metadata": {},
   "source": [
    "Run it from the project root with:\n",
    "\n",
    "```bash\n",
    "streamlit run 003_streamlit_ui/streamlit_basics_demo.py\n",
    "```\n",
    "\n",
    "Experiment by editing the file; Streamlit hot-reloads on save so students can see immediate feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3645d4",
   "metadata": {},
   "source": [
    "## Part 2 – Build the PDF RAG assistant\n",
    "With the widget basics in place, we now stitch together OpenAI embeddings + the Responses API to let users upload a PDF and ask grounded questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998644a7",
   "metadata": {},
   "source": [
    "### Connect to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import api_key\n",
    "\n",
    "client = OpenAI(api_key=api_key.openai)\n",
    "TEXT_MODEL = \"gpt-4o-mini\"\n",
    "EMBED_MODEL = \"text-embedding-3-large\"\n",
    "\n",
    "print(f\"Connected to OpenAI. Using {TEXT_MODEL} + {EMBED_MODEL}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792d3e5",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "These utilities chunk raw text, generate embeddings, perform cosine similarity, and call the Responses API with retrieved context. They mirror the logic used in the full Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Sequence, Tuple\n",
    "\n",
    "\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 900, overlap: int = 150) -> List[str]:\n",
    "    words = text.split()\n",
    "    chunks: List[str] = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(len(words), start + chunk_size)\n",
    "        chunk = \" \\\".join(words[start:end]).strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        if end >= len(words):\n",
    "            break\n",
    "        start = max(0, end - overlap)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "def embed_texts(texts: Sequence[str]) -> np.ndarray:\n",
    "    response = client.embeddings.create(model=EMBED_MODEL, input=list(texts))\n",
    "    return np.array([row.embedding for row in response.data], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "def top_chunks(query: str, chunks: Sequence[str], vectors: np.ndarray, k: int = 4) -> Tuple[List[str], np.ndarray]:\n",
    "    q_response = client.embeddings.create(model=EMBED_MODEL, input=[query])\n",
    "    q_vec = np.array(q_response.data[0].embedding, dtype=np.float32)\n",
    "    q_vec /= np.linalg.norm(q_vec) + 1e-10\n",
    "    chunk_norm = np.linalg.norm(vectors, axis=1, keepdims=True) + 1e-10\n",
    "    normalized = vectors / chunk_norm\n",
    "    sims = normalized @ q_vec\n",
    "    order = np.argsort(sims)[::-1][:k]\n",
    "    return [chunks[i] for i in order], sims[order]\n",
    "\n",
    "\n",
    "\n",
    "def answer_with_context(question: str, context_chunks: Sequence[str]) -> str:\n",
    "    context = \"\\n\\n\".join(context_chunks)\n",
    "    prompt = f\"\"\"Answer the question strictly with the provided context.\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nIf no answer is present, reply with 'I don't know'.\"\"\"\n",
    "    response = client.responses.create(\n",
    "        model=TEXT_MODEL, input=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.output_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0bcbf",
   "metadata": {},
   "source": [
    "### Quick dry-run in pure Python\n",
    "Simulate uploading a tiny “document” without launching Streamlit to prove that chunking, retrieval, and question answering work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_text = \"\"\"OpenAI builds advanced language models.\\n\\nThe design team ships sample apps to show how retrieval-augmented generation works.\\n\\nStreamlit makes it easy to turn Python scripts into shareable tools.\"\"\"\n",
    "chunks = chunk_text(demo_text, chunk_size=40, overlap=5)\n",
    "vectors = embed_texts(chunks)\n",
    "question = \"Which framework is used for shareable tools?\"\n",
    "retrieved, scores = top_chunks(question, chunks, vectors, k=2)\n",
    "answer = answer_with_context(question, retrieved)\n",
    "print(\"Chunks:\", chunks)\n",
    "print(\"Scores:\", np.round(scores, 3))\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3042747c",
   "metadata": {},
   "source": [
    "### Streamlit RAG UI file\n",
    "`003_streamlit_ui/rag_pdf_chat.py` brings everything together: file uploads, embeddings, retrieval, and the chat interface with expandable context panels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "rag_path = Path('003_streamlit_ui/rag_pdf_chat.py')\n",
    "print(rag_path.resolve())\n",
    "print(\"\\n\".join(rag_path.read_text().splitlines()[:40]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac9fcc",
   "metadata": {},
   "source": [
    "Launch the full experience once your API key is configured:\n",
    "\n",
    "```bash\n",
    "streamlit run 003_streamlit_ui/rag_pdf_chat.py\n",
    "```\n",
    "\n",
    "number of retrieved passages, or how answers are formatted to reinforce both Streamlit and RAG concepts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
